{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jLDisQ6gAaMQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "pwyZu2ibAhO1",
    "outputId": "01503b88-86a2-4619-d029-6ba8a7632cd8"
   },
   "outputs": [],
   "source": [
    "def loadIrisData():\n",
    "    iris = load_iris()\n",
    "    X=iris['data']\n",
    "    t=iris['target']\n",
    "    print(X.shape)\n",
    "    print(t.shape)\n",
    "    return X, t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "48_5__HzBks_"
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(t_indices, N):\n",
    "    '''\n",
    "    Inputs:\n",
    "        t_indices: list of indices\n",
    "        N: total no. of classes\n",
    "    '''\n",
    "    assert N>max(t_indices), (N, max(t_indices))\n",
    "    t_1hot=np.empty([len(t_indices),N])\n",
    "    for t in range(len(t_indices)):\n",
    "        l=np.zeros(N)\n",
    "        l[t_indices[t]]=1\n",
    "        t_1hot[t]=l\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "\n",
    "    return t_1hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m2DsnXa89lIk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_one_hot_encoding():\n",
    "    t_1hot = one_hot_encoding([0,2], 3)\n",
    "    t_1hotTrue = np.array([[1.,0.,0.], [0.,0.,1.]])\n",
    "    assert np.all(np.isclose( t_1hot, t_1hotTrue ))\n",
    "    print('Test passed', '\\U0001F44D')\n",
    "if __name__==\"__main__\":\n",
    "    test_one_hot_encoding()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VXxxA2YkB_I8"
   },
   "outputs": [],
   "source": [
    "def splitData(X,t,testFraction=0.2):\n",
    "    \"\"\"\n",
    "    Use numpy functions only\n",
    "    Inputs:\n",
    "        X: np array of shape (Nsamples, dim)\n",
    "        t: np array of len Nsamples; can be one hot vectors or labels\n",
    "        testFraction: (float) Nsamples_test = testFraction * Nsamples\n",
    "    \"\"\"\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "    index = np.arange(len(X))\n",
    "    np.random.shuffle(index)\n",
    "    Nsamples = X.shape[0]\n",
    "    Nsamples_test = int(testFraction*Nsamples)\n",
    "    index_test = index[:Nsamples_test]\n",
    "    index_train = index[Nsamples_test:]\n",
    "    X_train = np.zeros((len(index_train),len(X[0])))\n",
    "    X_test = np.zeros((len(index_test),len(X[0])))\n",
    "    t_train = np.zeros((len(index_train),len(t[0])))\n",
    "    t_test = np.zeros((len(index_test),len(t[0])))\n",
    "    for i in range(len(index_test)):\n",
    "        X_test[i] = X[index_test[i]]\n",
    "        t_test[i] = t[index_test[i]]\n",
    "    \n",
    "    for i in range(len(index_train)):\n",
    "        X_train[i] = X[index_train[i]]\n",
    "        t_train[i] = t[index_train[i]]\n",
    "    \n",
    "    return X_train, t_train, X_test, t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_splitData():\n",
    "    X = np.random.random((5,2))\n",
    "    t1hot = one_hot_encoding([1,0,2,1,2],3)\n",
    "    X_train, t1hot_train, X_test, t1hot_test = splitData(X,t1hot,.2)\n",
    "    assert X_train.shape==(4,2), [\"X_train.shape\", X_train.shape]\n",
    "    assert X_test.shape==(1,2), [\"X_test.shape\", X_test.shape]\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_splitData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OK2lZ6ZpCjAg"
   },
   "outputs": [],
   "source": [
    "### Normalize data to be of zero mean and unit variance\n",
    "def normalizeX(X_train, X_test):\n",
    "    '''\n",
    "    Inputs:\n",
    "        X_train: np array 2d\n",
    "        X_test: np array 2d\n",
    "    Outputs:\n",
    "        Normalized np arrays 2d\n",
    "    '''\n",
    "    mean_test = np.mean(X_test,axis = 0)\n",
    "    mean_train = np.mean(X_train, axis= 0)\n",
    "    std_test = np.std(X_test,axis=0)\n",
    "    std_train = np.std(X_train,axis=0)\n",
    "    X_train_normalized = (X_train-mean_train)/std_train\n",
    "    X_test_normalized = (X_test-mean_train)/std_train\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "\n",
    "    return X_train_normalized, X_test_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_normalizeX():\n",
    "    X_train = np.array([[1,1,0],[2,2,1]])\n",
    "    X_test = np.array([[1,1,0],[3,3,2]])\n",
    "    X_train_normalized, X_test_normalized = normalizeX(X_train, X_test)\n",
    "    a = np.array([[-1.,-1.,-1.], [ 1., 1., 1.]])\n",
    "    b = np.array([[-1.,-1.,-1.], [ 3.,3.,3.]])\n",
    "    assert np.all(np.isclose( X_train_normalized, a )), a\n",
    "    assert np.all(np.isclose( X_test_normalized, b )), b\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_normalizeX()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "AJ_OSEoQLEuc"
   },
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    '''\n",
    "    Input:\n",
    "        x: numpy array of any shape\n",
    "    Output:\n",
    "        y: numpy array of same shape as x\n",
    "    '''\n",
    "    y = 1/(1+np.exp(-x))\n",
    "    ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_sigmoid():\n",
    "    x = np.array([np.log(4),np.log(0.25),0])\n",
    "    y = sigmoid(x)\n",
    "    assert np.all(np.isclose( y, np.array([0.8, 0.2, 0.5]) )), y\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    '''\n",
    "    Input:\n",
    "        x: numpy array of any shape\n",
    "    Output:\n",
    "        y: numpy array of same shape as x\n",
    "    '''\n",
    "    div = sum(np.exp(x))\n",
    "    y = np.exp(x)/div\n",
    "    ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed üëç\n"
     ]
    }
   ],
   "source": [
    "def test_softmax():\n",
    "    x = np.array([np.log(2),np.log(7),0])\n",
    "    y = softmax(x)\n",
    "    assert np.all(np.isclose( y, np.array([0.2, 0.7, 0.1]) )), y\n",
    "    print('Test passed', '\\U0001F44D')    \n",
    "if __name__==\"__main__\":\n",
    "    test_softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iwi4QwxlOAOR"
   },
   "outputs": [],
   "source": [
    "def sigmoid_derivative(x):\n",
    "    '''\n",
    "    Input:\n",
    "        x: numpy array of any shape; it is sigmoid layer's output\n",
    "    Output:\n",
    "        y: numpy array of same shape as x; it is the derivative of sigmoid\n",
    "    '''\n",
    "    y = (x)*(1-x)\n",
    "    ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, ni, nh, no):\n",
    "        '''   \n",
    "        Input:\n",
    "            ni: int, size of input layer\n",
    "            nh: int, size of hidden layer\n",
    "            no: int, size of output layer\n",
    "        Action:\n",
    "            Creates instance variables\n",
    "        NOTE: We do not use bias explicitly here. Input x can have the first element 1 to have a bias term.\n",
    "        '''\n",
    "        self.ni = ni\n",
    "        self.nh = nh\n",
    "        self.no = no\n",
    "        self.weights1 = []\n",
    "        self.weights2 = []\n",
    "        return\n",
    "    \n",
    "    def init_weights(self):\n",
    "        '''\n",
    "        Action:\n",
    "            Randomly initialize weights1 and weights2 with proper size random np arrays\n",
    "        '''\n",
    "        self.weights1 =2*np.random.rand(self.nh,self.ni+1)-1\n",
    "        self.weights2 =2*np.random.rand(self.no,self.nh+1)-1\n",
    "         ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "\n",
    "    \n",
    "    def predict(self, x):\n",
    "        x = np.insert(x,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        h1 = self.weights1.dot(x)\n",
    "        v1 = sigmoid(h1)\n",
    "        v = v1\n",
    "        v1 = np.insert(v1,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        h2 = self.weights2.dot(v1)\n",
    "        v2 = softmax(h2)\n",
    "        return v2\n",
    "\n",
    "    def backprop(self,x,y,eta):\n",
    "        '''\n",
    "        # application of the chain rule to find derivative of the categorical cross entropy loss function with respect to weights2 and weights1\n",
    "        Input:\n",
    "            x: numpy array of shape (ni,1)\n",
    "            y: numpy array of shape (no,1)\n",
    "            eta: learning rate\n",
    "        Action:\n",
    "            # Finding the derivatives\n",
    "            del_weights2: np array that stores the derivative of the loss function with respect to weights2\n",
    "            del_weights1: np array that stores the derivative of the loss function with respect to weights1\n",
    "\n",
    "            # Update the weights with the derivative of the categorical cross entropy loss function\n",
    "              weights1 += eta*del_weights1\n",
    "              weights2 += eta*del_weights2\n",
    "        ''' \n",
    "        x1 = np.insert(x,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        h1 = self.weights1.dot(x1)\n",
    "        v1 = sigmoid(h1)\n",
    "        v = v1\n",
    "        v1 = np.insert(v1,0,1,axis=0) # inserts a row of 1s. This is for the bias\n",
    "        h2 = self.weights2.dot(v1)\n",
    "        v2 = softmax(h2)\n",
    "        \n",
    "        v2=v2.reshape((3,1))\n",
    "        v=v.reshape((5,1))\n",
    "        y=y.reshape((3,1))\n",
    "        bias1 = self.weights1[:,:1]\n",
    "        bias2 = self.weights2[:,:1]\n",
    "        w1 = self.weights1[:,1:]\n",
    "        w2 = self.weights2[:,1:]\n",
    "        del_weights2 = (y-v2).dot(v.T)\n",
    "        del_weights1 = sigmoid_derivative(v)*(w2.T.dot(y-v2))\n",
    "        \n",
    "        bias2 = bias2 + eta*(y-v2)\n",
    "        bias1 = bias1 + eta*del_weights1\n",
    "        \n",
    "        w1 = w1 + eta*del_weights1*(x.T)\n",
    "        w2 = w2 + eta*del_weights2\n",
    "        \n",
    "        self.weights1 = np.append(bias1,w1,axis=1)\n",
    "        self.weights2 = np.append(bias2,w2,axis=1)\n",
    "        \n",
    "        loss_val = (y*np.log(v2)).sum()\n",
    "        return loss_val\n",
    "        \n",
    "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "\n",
    "\n",
    "    def fit(self, X, t, eta, epochs):\n",
    "        '''\n",
    "        input:\n",
    "            X: training input data \n",
    "            t: training targets\n",
    "            eta: learning rate\n",
    "            epochs: number of epochs\n",
    "        Action:\n",
    "            train the weights\n",
    "        '''\n",
    "        loss = np.zeros(epochs)\n",
    "        self.init_weights()\n",
    "        number_of_samples = X.shape[0]\n",
    "        for i in range(number_of_samples):\n",
    "            for j in range(epochs):\n",
    "                x = X[i,:].T\n",
    "                y = t[i,:].T\n",
    "                loss_val = self.backprop(x,y,eta)\n",
    "                loss[j] = loss[j]-loss_val\n",
    "        ### WRITE YOUR CODE HERE - 5 MARKS\n",
    "        \n",
    "        loss=loss/(len(X))\n",
    "        return self.weights2, loss\n",
    "        \n",
    "    def predict_label(self,x):    \n",
    "        '''\n",
    "        Output:\n",
    "            y: np array of index\n",
    "        '''\n",
    "        y = np.zeros((len(x),1))\n",
    "        for i in range(len(x)):\n",
    "            v2 = self.predict(x[i])\n",
    "            y[i][0] = np.argmax(v2)\n",
    "        ### WRITE YOUR CODE HERE - 1 MARKS\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "fmR8F2JIFwqm",
    "outputId": "fa868689-92c8-4a43-882f-3321cde1a301"
   },
   "outputs": [],
   "source": [
    "### Lastly, report the accuracy of your model and print the Confusion Matrix\n",
    "#printing the confusion matrix\n",
    "def getCM(y,t):\n",
    "    '''\n",
    "    Inputs:\n",
    "        y: estimated labels np array (Nsample,1)\n",
    "        t: targets np array (Nsamples,1)\n",
    "    Outputs:\n",
    "        CM : np array of confusion matrix\n",
    "    '''\n",
    "    CM = np.zeros((3,3))\n",
    "    for i in range(len(y)):\n",
    "        CM[int(t[i][0])][int(y[i][0])] = CM[int(t[i][0])][int(y[i][0])] + 1\n",
    "    ### WRITE YOUR CODE HERE - 3 MARKS\n",
    "\n",
    "    return CM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_act(t):\n",
    "    y = np.zeros((len(t),1))\n",
    "    for i in range(len(t)):\n",
    "        y[i][0] = np.argmax(t[i])\n",
    "        \n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments\n",
    "Use the above functions to carry out the experiment:\n",
    "- load iris data and prepare it for NN\n",
    "- split randomly into 20% test data\n",
    "- create a NN with 1 hidden layer\n",
    "- train the network with training data\n",
    "- Plot loss w.r.t. number of epochs\n",
    "- Print confusion matrix on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "hewsBv12weZ2",
    "outputId": "52407420-e7e5-4ca6-952b-6448ffe4b101"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n",
      "[[ 8.  0.  0.]\n",
      " [ 0. 10.  0.]\n",
      " [ 0.  1. 11.]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def experiment():\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 10 MARKS\n",
    "    X,y=loadIrisData()\n",
    "    y_hot = one_hot_encoding(y,3)\n",
    "    X_train, y_hot_train, X_test, y_hot_test = splitData(X,y_hot,0.2)\n",
    "    X_train_normalized, X_test_normalized = normalizeX(X_train, X_test)\n",
    "    ni = X.shape[1]\n",
    "    no = 3\n",
    "    nh = 5\n",
    "    ni = 4\n",
    "    NN = NeuralNetwork(ni,nh,no)\n",
    "    weights2, Loss=NN.fit(X_train_normalized, y_hot_train,0.01,10000)\n",
    "    labels = np.empty([X_test.shape[0],1])\n",
    "    t = np.empty([X_test.shape[0],1])\n",
    "    labels = NN.predict_label(X_test_normalized)\n",
    "    t = predict_act(y_hot_test)\n",
    "    print(getCM(labels,t))\n",
    "    plt.plot(Loss)\n",
    "if __name__==\"__main__\":\n",
    "    experiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "BP_Iris.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
