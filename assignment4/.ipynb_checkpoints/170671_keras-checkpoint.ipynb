{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as K\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.datasets import load_iris\n",
    "import tensorflow as tf\n",
    "import tensorboard\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4)\n",
      "(150,)\n"
     ]
    }
   ],
   "source": [
    "def loadIrisData():\n",
    "    iris = load_iris()\n",
    "    X=iris['data']\n",
    "    t=iris['target']\n",
    "    print(X.shape)\n",
    "    print(t.shape)\n",
    "    return X, t\n",
    "X, t = loadIrisData()\n",
    "# np.insert(y,0,1,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encoding(t_indices, N):\n",
    "    '''\n",
    "    Inputs:\n",
    "        t_indices: list of indices\n",
    "        N: total no. of classes\n",
    "    '''\n",
    "    assert N>max(t_indices), (N, max(t_indices))\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "    one_hot_encoded = np.zeros((len(t_indices), N))\n",
    "    unique_list = np.unique(t_indices)\n",
    "    \n",
    "    for i in unique_list:\n",
    "        idx = np.where(t_indices==i)[0]\n",
    "#         print(idx)\n",
    "        one_hot_encoded[idx, i] = 1\n",
    "\n",
    "    t_1hot = one_hot_encoded\n",
    "    return t_1hot\n",
    "t = one_hot_encoding(t, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitData(X,t,testFraction=0.2):\n",
    "    \"\"\"\n",
    "    Use numpy functions only\n",
    "    Inputs:\n",
    "        X: np array of shape (Nsamples, dim)\n",
    "        t: np array of len Nsamples; can be one hot vectors or labels\n",
    "        testFraction: (float) Nsamples_test = testFraction * Nsamples\n",
    "    \"\"\"\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "#     print(np.floor(len(X)*testFraction))\n",
    "    arr = np.arange(len(X))\n",
    "    np.random.shuffle(arr)\n",
    "    X = X[arr]\n",
    "    t = t[arr]\n",
    "    \n",
    "    X_test = X[:int(np.floor(testFraction*len(X))), :]\n",
    "    t_test = t[:int(np.floor(testFraction*len(t))), :]\n",
    "    \n",
    "    X_train = X[int(np.floor(testFraction*len(X))):, :]\n",
    "    t_train = t[int(np.floor(testFraction*len(t))):, :]\n",
    "    \n",
    "    return X_train, t_train, X_test, t_test\n",
    "\n",
    "X_train, t_train, X_test, t_test = splitData(X, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Normalize data to be of zero mean and unit variance\n",
    "def normalizeX(X_train, X_test):\n",
    "    '''\n",
    "    Inputs:\n",
    "        X_train: np array 2d\n",
    "        X_test: np array 2d\n",
    "    Outputs:\n",
    "        Normalized np arrays 2d\n",
    "    '''\n",
    "\n",
    "    ### WRITE YOUR CODE HERE - 2 MARKS\n",
    "    \n",
    "    X_test_normalized = (X_test-np.float32([np.mean(X_test, axis=0)]))\n",
    "    X_test_normalized = X_test_normalized/np.float32([np.std(X_test_normalized, axis=0)])\n",
    "    X_train_normalized = (X_train-np.float32([np.mean(X_train, axis=0)]))\n",
    "    X_train_normalized = X_train_normalized/np.float32([np.std(X_train_normalized, axis=0)])\n",
    "\n",
    "    return X_train_normalized, X_test_normalized\n",
    "\n",
    "X_train, X_test = normalizeX(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sigmoid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10, input_dim=4, activation=tf.keras.layers.Activation('sigmoid')))\n",
    "model.add(tf.keras.layers.Dense(3, activation=tf.keras.layers.Activation('sigmoid')))\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logdir_sigmoid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.RMSprop(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0923 13:35:56.278172 139682939295552 summary_ops_v2.py:1110] Model failed to serialize as JSON. Ignoring... 'Activation' object has no attribute '__name__'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 0s 2ms/sample - loss: 1.1051 - accuracy: 0.1167 - val_loss: 1.0830 - val_accuracy: 0.2000\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 88us/sample - loss: 1.0978 - accuracy: 0.1583 - val_loss: 1.0782 - val_accuracy: 0.3333\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 1.0927 - accuracy: 0.2583 - val_loss: 1.0742 - val_accuracy: 0.3333\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 1.0884 - accuracy: 0.2000 - val_loss: 1.0705 - val_accuracy: 0.3333\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 1.0840 - accuracy: 0.2917 - val_loss: 1.0672 - val_accuracy: 0.3667\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 1.0803 - accuracy: 0.3000 - val_loss: 1.0639 - val_accuracy: 0.3667\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 160us/sample - loss: 1.0764 - accuracy: 0.3250 - val_loss: 1.0607 - val_accuracy: 0.3667\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 1.0728 - accuracy: 0.3250 - val_loss: 1.0574 - val_accuracy: 0.3667\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 94us/sample - loss: 1.0691 - accuracy: 0.3250 - val_loss: 1.0541 - val_accuracy: 0.3667\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 71us/sample - loss: 1.0655 - accuracy: 0.3250 - val_loss: 1.0508 - val_accuracy: 0.3667\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 66us/sample - loss: 1.0618 - accuracy: 0.3250 - val_loss: 1.0476 - val_accuracy: 0.3667\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 62us/sample - loss: 1.0586 - accuracy: 0.3250 - val_loss: 1.0446 - val_accuracy: 0.3667\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 87us/sample - loss: 1.0549 - accuracy: 0.3250 - val_loss: 1.0415 - val_accuracy: 0.3667\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 94us/sample - loss: 1.0514 - accuracy: 0.3250 - val_loss: 1.0383 - val_accuracy: 0.3667\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 71us/sample - loss: 1.0482 - accuracy: 0.3250 - val_loss: 1.0351 - val_accuracy: 0.3667\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 74us/sample - loss: 1.0446 - accuracy: 0.3250 - val_loss: 1.0320 - val_accuracy: 0.3667\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 75us/sample - loss: 1.0412 - accuracy: 0.3250 - val_loss: 1.0288 - val_accuracy: 0.3667\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 93us/sample - loss: 1.0379 - accuracy: 0.3250 - val_loss: 1.0257 - val_accuracy: 0.3667\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 88us/sample - loss: 1.0346 - accuracy: 0.3250 - val_loss: 1.0227 - val_accuracy: 0.3667\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 1.0311 - accuracy: 0.3250 - val_loss: 1.0196 - val_accuracy: 0.3667\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 82us/sample - loss: 1.0277 - accuracy: 0.3250 - val_loss: 1.0164 - val_accuracy: 0.3667\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 1.0242 - accuracy: 0.3333 - val_loss: 1.0132 - val_accuracy: 0.3667\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 1.0208 - accuracy: 0.3333 - val_loss: 1.0099 - val_accuracy: 0.3667\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 1.0173 - accuracy: 0.3333 - val_loss: 1.0066 - val_accuracy: 0.3667\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 1.0138 - accuracy: 0.3333 - val_loss: 1.0033 - val_accuracy: 0.3667\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 1.0104 - accuracy: 0.3333 - val_loss: 1.0001 - val_accuracy: 0.3667\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 91us/sample - loss: 1.0068 - accuracy: 0.3583 - val_loss: 0.9968 - val_accuracy: 0.4000\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 1.0035 - accuracy: 0.3583 - val_loss: 0.9935 - val_accuracy: 0.4000\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 80us/sample - loss: 0.9998 - accuracy: 0.3833 - val_loss: 0.9901 - val_accuracy: 0.4000\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 0.9965 - accuracy: 0.3917 - val_loss: 0.9868 - val_accuracy: 0.4667\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.9928 - accuracy: 0.4250 - val_loss: 0.9835 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.9895 - accuracy: 0.4500 - val_loss: 0.9802 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.9859 - accuracy: 0.4750 - val_loss: 0.9769 - val_accuracy: 0.5667\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 0.9825 - accuracy: 0.4833 - val_loss: 0.9735 - val_accuracy: 0.5667\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 0.9789 - accuracy: 0.5083 - val_loss: 0.9700 - val_accuracy: 0.5667\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 91us/sample - loss: 0.9752 - accuracy: 0.5083 - val_loss: 0.9664 - val_accuracy: 0.5667\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 85us/sample - loss: 0.9716 - accuracy: 0.5083 - val_loss: 0.9630 - val_accuracy: 0.5667\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 96us/sample - loss: 0.9679 - accuracy: 0.5333 - val_loss: 0.9594 - val_accuracy: 0.6000\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 96us/sample - loss: 0.9644 - accuracy: 0.5500 - val_loss: 0.9558 - val_accuracy: 0.6333\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.9607 - accuracy: 0.5500 - val_loss: 0.9523 - val_accuracy: 0.6333\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 95us/sample - loss: 0.9571 - accuracy: 0.5833 - val_loss: 0.9488 - val_accuracy: 0.6667\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.9536 - accuracy: 0.5917 - val_loss: 0.9453 - val_accuracy: 0.6333\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 0.9499 - accuracy: 0.6000 - val_loss: 0.9418 - val_accuracy: 0.6333\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 93us/sample - loss: 0.9462 - accuracy: 0.6250 - val_loss: 0.9383 - val_accuracy: 0.6333\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.9428 - accuracy: 0.6500 - val_loss: 0.9347 - val_accuracy: 0.6333\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 94us/sample - loss: 0.9390 - accuracy: 0.6833 - val_loss: 0.9311 - val_accuracy: 0.6333\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.9353 - accuracy: 0.6750 - val_loss: 0.9275 - val_accuracy: 0.7000\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 91us/sample - loss: 0.9316 - accuracy: 0.6833 - val_loss: 0.9238 - val_accuracy: 0.7000\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.9280 - accuracy: 0.6917 - val_loss: 0.9201 - val_accuracy: 0.7333\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 79us/sample - loss: 0.9243 - accuracy: 0.7083 - val_loss: 0.9164 - val_accuracy: 0.7333\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 0.9205 - accuracy: 0.7083 - val_loss: 0.9127 - val_accuracy: 0.7667\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.9170 - accuracy: 0.7000 - val_loss: 0.9091 - val_accuracy: 0.7667\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.9132 - accuracy: 0.7417 - val_loss: 0.9055 - val_accuracy: 0.7667\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.9096 - accuracy: 0.7417 - val_loss: 0.9019 - val_accuracy: 0.8333\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 79us/sample - loss: 0.9060 - accuracy: 0.7417 - val_loss: 0.8982 - val_accuracy: 0.8333\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.9023 - accuracy: 0.7417 - val_loss: 0.8946 - val_accuracy: 0.8333\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.8987 - accuracy: 0.7500 - val_loss: 0.8909 - val_accuracy: 0.8333\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 93us/sample - loss: 0.8949 - accuracy: 0.7583 - val_loss: 0.8871 - val_accuracy: 0.8333\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 89us/sample - loss: 0.8912 - accuracy: 0.7667 - val_loss: 0.8833 - val_accuracy: 0.8333\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.8875 - accuracy: 0.7750 - val_loss: 0.8797 - val_accuracy: 0.8333\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 101us/sample - loss: 0.8837 - accuracy: 0.7917 - val_loss: 0.8759 - val_accuracy: 0.8333\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 102us/sample - loss: 0.8800 - accuracy: 0.7917 - val_loss: 0.8722 - val_accuracy: 0.8333\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.8762 - accuracy: 0.8083 - val_loss: 0.8684 - val_accuracy: 0.8333\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.8725 - accuracy: 0.8333 - val_loss: 0.8646 - val_accuracy: 0.8333\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 0.8688 - accuracy: 0.8500 - val_loss: 0.8608 - val_accuracy: 0.8333\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 0.8649 - accuracy: 0.8333 - val_loss: 0.8570 - val_accuracy: 0.8333\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.8612 - accuracy: 0.8417 - val_loss: 0.8531 - val_accuracy: 0.8333\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 137us/sample - loss: 0.8574 - accuracy: 0.8417 - val_loss: 0.8493 - val_accuracy: 0.8000\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.8535 - accuracy: 0.8500 - val_loss: 0.8453 - val_accuracy: 0.8333\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.8497 - accuracy: 0.8500 - val_loss: 0.8414 - val_accuracy: 0.8333\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.8459 - accuracy: 0.8417 - val_loss: 0.8375 - val_accuracy: 0.8333\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 0.8419 - accuracy: 0.8417 - val_loss: 0.8335 - val_accuracy: 0.8333\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 0.8383 - accuracy: 0.8417 - val_loss: 0.8296 - val_accuracy: 0.8333\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.8341 - accuracy: 0.8417 - val_loss: 0.8257 - val_accuracy: 0.8333\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.8303 - accuracy: 0.8583 - val_loss: 0.8216 - val_accuracy: 0.8333\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 127us/sample - loss: 0.8264 - accuracy: 0.8500 - val_loss: 0.8176 - val_accuracy: 0.8333\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.8226 - accuracy: 0.8583 - val_loss: 0.8137 - val_accuracy: 0.8333\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.8188 - accuracy: 0.8500 - val_loss: 0.8098 - val_accuracy: 0.8333\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 122us/sample - loss: 0.8149 - accuracy: 0.8500 - val_loss: 0.8059 - val_accuracy: 0.8333\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 114us/sample - loss: 0.8110 - accuracy: 0.8500 - val_loss: 0.8019 - val_accuracy: 0.8333\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 98us/sample - loss: 0.8071 - accuracy: 0.8417 - val_loss: 0.7980 - val_accuracy: 0.8333\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.8034 - accuracy: 0.8417 - val_loss: 0.7940 - val_accuracy: 0.8333\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.7995 - accuracy: 0.8417 - val_loss: 0.7902 - val_accuracy: 0.8333\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.7957 - accuracy: 0.8417 - val_loss: 0.7863 - val_accuracy: 0.8333\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.7918 - accuracy: 0.8500 - val_loss: 0.7824 - val_accuracy: 0.8333\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 126us/sample - loss: 0.7880 - accuracy: 0.8500 - val_loss: 0.7785 - val_accuracy: 0.8333\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.7842 - accuracy: 0.8500 - val_loss: 0.7746 - val_accuracy: 0.8333\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.7804 - accuracy: 0.8500 - val_loss: 0.7707 - val_accuracy: 0.8333\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 97us/sample - loss: 0.7765 - accuracy: 0.8500 - val_loss: 0.7667 - val_accuracy: 0.8333\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.7726 - accuracy: 0.8500 - val_loss: 0.7628 - val_accuracy: 0.8333\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 86us/sample - loss: 0.7688 - accuracy: 0.8583 - val_loss: 0.7587 - val_accuracy: 0.8333\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.7648 - accuracy: 0.8667 - val_loss: 0.7546 - val_accuracy: 0.8333\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.7608 - accuracy: 0.8667 - val_loss: 0.7504 - val_accuracy: 0.8333\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 129us/sample - loss: 0.7569 - accuracy: 0.8667 - val_loss: 0.7463 - val_accuracy: 0.8333\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 0.7529 - accuracy: 0.8667 - val_loss: 0.7422 - val_accuracy: 0.8333\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 0.7490 - accuracy: 0.8667 - val_loss: 0.7383 - val_accuracy: 0.8333\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.7454 - accuracy: 0.8750 - val_loss: 0.7345 - val_accuracy: 0.8333\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.7415 - accuracy: 0.8750 - val_loss: 0.7307 - val_accuracy: 0.8333\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.7378 - accuracy: 0.8917 - val_loss: 0.7268 - val_accuracy: 0.8333\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 149us/sample - loss: 0.7340 - accuracy: 0.8833 - val_loss: 0.7230 - val_accuracy: 0.8333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f097478d748>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=t_train, validation_data=(X_test, t_test), epochs=100, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6012 (pid 6871), started 0:07:48 ago. (Use '!kill 6871' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6012\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f09737fc128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir=./logdir_sigmoid/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X)\n",
    "confusion_matrix(t, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Dense(10, input_dim=4, activation=tf.keras.layers.Activation('sigmoid')))\n",
    "model.add(tf.keras.layers.Dense(3, activation=tf.keras.layers.Activation('softmax')))\n",
    "\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir='./logdir')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.optimizers.RMSprop(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0923 13:31:59.140554 139682939295552 summary_ops_v2.py:1110] Model failed to serialize as JSON. Ignoring... 'Activation' object has no attribute '__name__'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 120 samples, validate on 30 samples\n",
      "Epoch 1/100\n",
      "120/120 [==============================] - 0s 2ms/sample - loss: 1.3479 - accuracy: 0.3250 - val_loss: 1.1930 - val_accuracy: 0.3667\n",
      "Epoch 2/100\n",
      "120/120 [==============================] - 0s 91us/sample - loss: 1.3254 - accuracy: 0.3250 - val_loss: 1.1828 - val_accuracy: 0.3667\n",
      "Epoch 3/100\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 1.3090 - accuracy: 0.3250 - val_loss: 1.1755 - val_accuracy: 0.3667\n",
      "Epoch 4/100\n",
      "120/120 [==============================] - 0s 135us/sample - loss: 1.2954 - accuracy: 0.3167 - val_loss: 1.1683 - val_accuracy: 0.3333\n",
      "Epoch 5/100\n",
      "120/120 [==============================] - 0s 219us/sample - loss: 1.2823 - accuracy: 0.3250 - val_loss: 1.1624 - val_accuracy: 0.3333\n",
      "Epoch 6/100\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 1.2709 - accuracy: 0.3250 - val_loss: 1.1562 - val_accuracy: 0.3333\n",
      "Epoch 7/100\n",
      "120/120 [==============================] - 0s 79us/sample - loss: 1.2602 - accuracy: 0.3167 - val_loss: 1.1502 - val_accuracy: 0.3333\n",
      "Epoch 8/100\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 1.2497 - accuracy: 0.3167 - val_loss: 1.1446 - val_accuracy: 0.3333\n",
      "Epoch 9/100\n",
      "120/120 [==============================] - 0s 100us/sample - loss: 1.2389 - accuracy: 0.3167 - val_loss: 1.1389 - val_accuracy: 0.3333\n",
      "Epoch 10/100\n",
      "120/120 [==============================] - 0s 92us/sample - loss: 1.2289 - accuracy: 0.3167 - val_loss: 1.1332 - val_accuracy: 0.3333\n",
      "Epoch 11/100\n",
      "120/120 [==============================] - 0s 65us/sample - loss: 1.2183 - accuracy: 0.3167 - val_loss: 1.1281 - val_accuracy: 0.3333\n",
      "Epoch 12/100\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 1.2085 - accuracy: 0.3167 - val_loss: 1.1230 - val_accuracy: 0.3333\n",
      "Epoch 13/100\n",
      "120/120 [==============================] - 0s 144us/sample - loss: 1.1987 - accuracy: 0.3167 - val_loss: 1.1177 - val_accuracy: 0.3333\n",
      "Epoch 14/100\n",
      "120/120 [==============================] - 0s 66us/sample - loss: 1.1891 - accuracy: 0.3167 - val_loss: 1.1124 - val_accuracy: 0.3333\n",
      "Epoch 15/100\n",
      "120/120 [==============================] - 0s 84us/sample - loss: 1.1793 - accuracy: 0.3167 - val_loss: 1.1073 - val_accuracy: 0.3333\n",
      "Epoch 16/100\n",
      "120/120 [==============================] - 0s 139us/sample - loss: 1.1705 - accuracy: 0.3167 - val_loss: 1.1024 - val_accuracy: 0.3333\n",
      "Epoch 17/100\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 1.1621 - accuracy: 0.3167 - val_loss: 1.0975 - val_accuracy: 0.3333\n",
      "Epoch 18/100\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 1.1526 - accuracy: 0.3167 - val_loss: 1.0925 - val_accuracy: 0.3000\n",
      "Epoch 19/100\n",
      "120/120 [==============================] - 0s 95us/sample - loss: 1.1440 - accuracy: 0.3167 - val_loss: 1.0878 - val_accuracy: 0.3667\n",
      "Epoch 20/100\n",
      "120/120 [==============================] - 0s 83us/sample - loss: 1.1359 - accuracy: 0.3167 - val_loss: 1.0829 - val_accuracy: 0.3333\n",
      "Epoch 21/100\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 1.1275 - accuracy: 0.3167 - val_loss: 1.0783 - val_accuracy: 0.3333\n",
      "Epoch 22/100\n",
      "120/120 [==============================] - 0s 72us/sample - loss: 1.1195 - accuracy: 0.3167 - val_loss: 1.0741 - val_accuracy: 0.3667\n",
      "Epoch 23/100\n",
      "120/120 [==============================] - 0s 94us/sample - loss: 1.1111 - accuracy: 0.3167 - val_loss: 1.0691 - val_accuracy: 0.3667\n",
      "Epoch 24/100\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 1.1032 - accuracy: 0.3167 - val_loss: 1.0646 - val_accuracy: 0.3667\n",
      "Epoch 25/100\n",
      "120/120 [==============================] - 0s 85us/sample - loss: 1.0949 - accuracy: 0.3250 - val_loss: 1.0600 - val_accuracy: 0.3667\n",
      "Epoch 26/100\n",
      "120/120 [==============================] - 0s 109us/sample - loss: 1.0868 - accuracy: 0.3333 - val_loss: 1.0550 - val_accuracy: 0.4000\n",
      "Epoch 27/100\n",
      "120/120 [==============================] - 0s 91us/sample - loss: 1.0794 - accuracy: 0.3333 - val_loss: 1.0499 - val_accuracy: 0.4000\n",
      "Epoch 28/100\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 1.0721 - accuracy: 0.3500 - val_loss: 1.0456 - val_accuracy: 0.4000\n",
      "Epoch 29/100\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 1.0638 - accuracy: 0.4000 - val_loss: 1.0409 - val_accuracy: 0.4000\n",
      "Epoch 30/100\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 1.0566 - accuracy: 0.4583 - val_loss: 1.0359 - val_accuracy: 0.4667\n",
      "Epoch 31/100\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 1.0493 - accuracy: 0.5000 - val_loss: 1.0312 - val_accuracy: 0.5000\n",
      "Epoch 32/100\n",
      "120/120 [==============================] - 0s 88us/sample - loss: 1.0413 - accuracy: 0.5750 - val_loss: 1.0268 - val_accuracy: 0.5000\n",
      "Epoch 33/100\n",
      "120/120 [==============================] - 0s 131us/sample - loss: 1.0345 - accuracy: 0.6167 - val_loss: 1.0210 - val_accuracy: 0.5333\n",
      "Epoch 34/100\n",
      "120/120 [==============================] - 0s 96us/sample - loss: 1.0271 - accuracy: 0.6417 - val_loss: 1.0162 - val_accuracy: 0.5333\n",
      "Epoch 35/100\n",
      "120/120 [==============================] - 0s 93us/sample - loss: 1.0197 - accuracy: 0.6500 - val_loss: 1.0112 - val_accuracy: 0.5333\n",
      "Epoch 36/100\n",
      "120/120 [==============================] - 0s 113us/sample - loss: 1.0122 - accuracy: 0.6583 - val_loss: 1.0065 - val_accuracy: 0.5333\n",
      "Epoch 37/100\n",
      "120/120 [==============================] - 0s 96us/sample - loss: 1.0061 - accuracy: 0.6750 - val_loss: 1.0016 - val_accuracy: 0.5333\n",
      "Epoch 38/100\n",
      "120/120 [==============================] - 0s 87us/sample - loss: 0.9979 - accuracy: 0.6750 - val_loss: 0.9968 - val_accuracy: 0.5000\n",
      "Epoch 39/100\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.9915 - accuracy: 0.6917 - val_loss: 0.9925 - val_accuracy: 0.5333\n",
      "Epoch 40/100\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.9840 - accuracy: 0.6917 - val_loss: 0.9874 - val_accuracy: 0.5667\n",
      "Epoch 41/100\n",
      "120/120 [==============================] - 0s 107us/sample - loss: 0.9772 - accuracy: 0.6917 - val_loss: 0.9827 - val_accuracy: 0.5667\n",
      "Epoch 42/100\n",
      "120/120 [==============================] - 0s 104us/sample - loss: 0.9703 - accuracy: 0.6917 - val_loss: 0.9775 - val_accuracy: 0.5667\n",
      "Epoch 43/100\n",
      "120/120 [==============================] - 0s 110us/sample - loss: 0.9639 - accuracy: 0.6833 - val_loss: 0.9728 - val_accuracy: 0.5667\n",
      "Epoch 44/100\n",
      "120/120 [==============================] - 0s 126us/sample - loss: 0.9566 - accuracy: 0.6917 - val_loss: 0.9679 - val_accuracy: 0.6000\n",
      "Epoch 45/100\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.9502 - accuracy: 0.7000 - val_loss: 0.9624 - val_accuracy: 0.6000\n",
      "Epoch 46/100\n",
      "120/120 [==============================] - 0s 146us/sample - loss: 0.9433 - accuracy: 0.6917 - val_loss: 0.9568 - val_accuracy: 0.6000\n",
      "Epoch 47/100\n",
      "120/120 [==============================] - 0s 98us/sample - loss: 0.9369 - accuracy: 0.7000 - val_loss: 0.9511 - val_accuracy: 0.6000\n",
      "Epoch 48/100\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.9309 - accuracy: 0.7000 - val_loss: 0.9458 - val_accuracy: 0.6000\n",
      "Epoch 49/100\n",
      "120/120 [==============================] - 0s 155us/sample - loss: 0.9238 - accuracy: 0.7083 - val_loss: 0.9411 - val_accuracy: 0.6000\n",
      "Epoch 50/100\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.9175 - accuracy: 0.7000 - val_loss: 0.9356 - val_accuracy: 0.6000\n",
      "Epoch 51/100\n",
      "120/120 [==============================] - 0s 93us/sample - loss: 0.9107 - accuracy: 0.7083 - val_loss: 0.9309 - val_accuracy: 0.6000\n",
      "Epoch 52/100\n",
      "120/120 [==============================] - 0s 94us/sample - loss: 0.9047 - accuracy: 0.7167 - val_loss: 0.9253 - val_accuracy: 0.6333\n",
      "Epoch 53/100\n",
      "120/120 [==============================] - 0s 116us/sample - loss: 0.8985 - accuracy: 0.7250 - val_loss: 0.9197 - val_accuracy: 0.6333\n",
      "Epoch 54/100\n",
      "120/120 [==============================] - 0s 90us/sample - loss: 0.8926 - accuracy: 0.7250 - val_loss: 0.9145 - val_accuracy: 0.6333\n",
      "Epoch 55/100\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.8858 - accuracy: 0.7250 - val_loss: 0.9096 - val_accuracy: 0.6000\n",
      "Epoch 56/100\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.8802 - accuracy: 0.7250 - val_loss: 0.9044 - val_accuracy: 0.6333\n",
      "Epoch 57/100\n",
      "120/120 [==============================] - 0s 112us/sample - loss: 0.8736 - accuracy: 0.7500 - val_loss: 0.8996 - val_accuracy: 0.6667\n",
      "Epoch 58/100\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.8681 - accuracy: 0.7333 - val_loss: 0.8954 - val_accuracy: 0.6333\n",
      "Epoch 59/100\n",
      "120/120 [==============================] - 0s 223us/sample - loss: 0.8621 - accuracy: 0.7500 - val_loss: 0.8908 - val_accuracy: 0.6333\n",
      "Epoch 60/100\n",
      "120/120 [==============================] - 0s 147us/sample - loss: 0.8553 - accuracy: 0.7500 - val_loss: 0.8857 - val_accuracy: 0.6333\n",
      "Epoch 61/100\n",
      "120/120 [==============================] - 0s 199us/sample - loss: 0.8493 - accuracy: 0.7500 - val_loss: 0.8809 - val_accuracy: 0.6000\n",
      "Epoch 62/100\n",
      "120/120 [==============================] - 0s 118us/sample - loss: 0.8436 - accuracy: 0.7500 - val_loss: 0.8763 - val_accuracy: 0.6333\n",
      "Epoch 63/100\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.8373 - accuracy: 0.7583 - val_loss: 0.8710 - val_accuracy: 0.6333\n",
      "Epoch 64/100\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.8315 - accuracy: 0.7583 - val_loss: 0.8669 - val_accuracy: 0.6333\n",
      "Epoch 65/100\n",
      "120/120 [==============================] - 0s 128us/sample - loss: 0.8252 - accuracy: 0.7583 - val_loss: 0.8613 - val_accuracy: 0.6333\n",
      "Epoch 66/100\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.8192 - accuracy: 0.7583 - val_loss: 0.8556 - val_accuracy: 0.6333\n",
      "Epoch 67/100\n",
      "120/120 [==============================] - 0s 123us/sample - loss: 0.8135 - accuracy: 0.7583 - val_loss: 0.8503 - val_accuracy: 0.6333\n",
      "Epoch 68/100\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.8076 - accuracy: 0.7500 - val_loss: 0.8453 - val_accuracy: 0.6333\n",
      "Epoch 69/100\n",
      "120/120 [==============================] - 0s 132us/sample - loss: 0.8015 - accuracy: 0.7750 - val_loss: 0.8396 - val_accuracy: 0.6333\n",
      "Epoch 70/100\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.7960 - accuracy: 0.7667 - val_loss: 0.8345 - val_accuracy: 0.6333\n",
      "Epoch 71/100\n",
      "120/120 [==============================] - 0s 115us/sample - loss: 0.7914 - accuracy: 0.7667 - val_loss: 0.8296 - val_accuracy: 0.6667\n",
      "Epoch 72/100\n",
      "120/120 [==============================] - 0s 86us/sample - loss: 0.7844 - accuracy: 0.7750 - val_loss: 0.8252 - val_accuracy: 0.6667\n",
      "Epoch 73/100\n",
      "120/120 [==============================] - 0s 90us/sample - loss: 0.7793 - accuracy: 0.7750 - val_loss: 0.8201 - val_accuracy: 0.7000\n",
      "Epoch 74/100\n",
      "120/120 [==============================] - 0s 148us/sample - loss: 0.7737 - accuracy: 0.7833 - val_loss: 0.8159 - val_accuracy: 0.7000\n",
      "Epoch 75/100\n",
      "120/120 [==============================] - 0s 90us/sample - loss: 0.7681 - accuracy: 0.7750 - val_loss: 0.8113 - val_accuracy: 0.7000\n",
      "Epoch 76/100\n",
      "120/120 [==============================] - 0s 141us/sample - loss: 0.7630 - accuracy: 0.7750 - val_loss: 0.8060 - val_accuracy: 0.7000\n",
      "Epoch 77/100\n",
      "120/120 [==============================] - 0s 103us/sample - loss: 0.7570 - accuracy: 0.7917 - val_loss: 0.8015 - val_accuracy: 0.7333\n",
      "Epoch 78/100\n",
      "120/120 [==============================] - 0s 119us/sample - loss: 0.7520 - accuracy: 0.7917 - val_loss: 0.7972 - val_accuracy: 0.7333\n",
      "Epoch 79/100\n",
      "120/120 [==============================] - 0s 120us/sample - loss: 0.7464 - accuracy: 0.8000 - val_loss: 0.7925 - val_accuracy: 0.7333\n",
      "Epoch 80/100\n",
      "120/120 [==============================] - 0s 143us/sample - loss: 0.7410 - accuracy: 0.8083 - val_loss: 0.7884 - val_accuracy: 0.7333\n",
      "Epoch 81/100\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.7362 - accuracy: 0.8000 - val_loss: 0.7833 - val_accuracy: 0.7333\n",
      "Epoch 82/100\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7303 - accuracy: 0.8083 - val_loss: 0.7780 - val_accuracy: 0.7333\n",
      "Epoch 83/100\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 0.7251 - accuracy: 0.8250 - val_loss: 0.7730 - val_accuracy: 0.7667\n",
      "Epoch 84/100\n",
      "120/120 [==============================] - 0s 130us/sample - loss: 0.7197 - accuracy: 0.8250 - val_loss: 0.7681 - val_accuracy: 0.7667\n",
      "Epoch 85/100\n",
      "120/120 [==============================] - 0s 121us/sample - loss: 0.7150 - accuracy: 0.8250 - val_loss: 0.7629 - val_accuracy: 0.7667\n",
      "Epoch 86/100\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.7096 - accuracy: 0.8250 - val_loss: 0.7585 - val_accuracy: 0.7667\n",
      "Epoch 87/100\n",
      "120/120 [==============================] - 0s 106us/sample - loss: 0.7042 - accuracy: 0.8250 - val_loss: 0.7544 - val_accuracy: 0.7667\n",
      "Epoch 88/100\n",
      "120/120 [==============================] - 0s 111us/sample - loss: 0.6998 - accuracy: 0.8250 - val_loss: 0.7494 - val_accuracy: 0.8000\n",
      "Epoch 89/100\n",
      "120/120 [==============================] - 0s 89us/sample - loss: 0.6943 - accuracy: 0.8250 - val_loss: 0.7444 - val_accuracy: 0.8000\n",
      "Epoch 90/100\n",
      "120/120 [==============================] - 0s 131us/sample - loss: 0.6900 - accuracy: 0.8250 - val_loss: 0.7407 - val_accuracy: 0.8000\n",
      "Epoch 91/100\n",
      "120/120 [==============================] - 0s 105us/sample - loss: 0.6848 - accuracy: 0.8167 - val_loss: 0.7366 - val_accuracy: 0.8000\n",
      "Epoch 92/100\n",
      "120/120 [==============================] - 0s 79us/sample - loss: 0.6801 - accuracy: 0.8250 - val_loss: 0.7316 - val_accuracy: 0.8000\n",
      "Epoch 93/100\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.6750 - accuracy: 0.8167 - val_loss: 0.7274 - val_accuracy: 0.8000\n",
      "Epoch 94/100\n",
      "120/120 [==============================] - 0s 124us/sample - loss: 0.6703 - accuracy: 0.8167 - val_loss: 0.7224 - val_accuracy: 0.8000\n",
      "Epoch 95/100\n",
      "120/120 [==============================] - 0s 149us/sample - loss: 0.6661 - accuracy: 0.8167 - val_loss: 0.7180 - val_accuracy: 0.8000\n",
      "Epoch 96/100\n",
      "120/120 [==============================] - 0s 99us/sample - loss: 0.6608 - accuracy: 0.8167 - val_loss: 0.7138 - val_accuracy: 0.8000\n",
      "Epoch 97/100\n",
      "120/120 [==============================] - 0s 157us/sample - loss: 0.6571 - accuracy: 0.8167 - val_loss: 0.7092 - val_accuracy: 0.8000\n",
      "Epoch 98/100\n",
      "120/120 [==============================] - 0s 98us/sample - loss: 0.6522 - accuracy: 0.8167 - val_loss: 0.7056 - val_accuracy: 0.8000\n",
      "Epoch 99/100\n",
      "120/120 [==============================] - 0s 140us/sample - loss: 0.6473 - accuracy: 0.8167 - val_loss: 0.7011 - val_accuracy: 0.8000\n",
      "Epoch 100/100\n",
      "120/120 [==============================] - 0s 98us/sample - loss: 0.6432 - accuracy: 0.8167 - val_loss: 0.6972 - val_accuracy: 0.8000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f0973b23e10>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=t_train, validation_data=(X_test, t_test), epochs=100, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6011 (pid 6782), started 0:06:26 ago. (Use '!kill 6782' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:6011\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7f097478e2b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# logdir='./logdir'\n",
    "# %load_ext tensorboard\n",
    "%tensorboard --logdir=./logdir/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
